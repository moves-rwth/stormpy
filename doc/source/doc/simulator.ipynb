{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%md\n"
    }
   },
   "source": [
    "# Working with Simulators\n",
    "\n",
    "The simulators in stormpy are meant to mimic access to unknown models,\n",
    "but they can also be used to explore the model.\n",
    "\n",
    "All simulators implement the abstract class `stormpy.simulator.Simulator`. \n",
    "\n",
    "The simulators differ in the model representation they use in the background and in the representation of the states and actions exposed to the user. We will go through some options by example!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stormpy\n",
    "import stormpy.examples\n",
    "import stormpy.examples.files\n",
    "import stormpy.simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based simulation\n",
    "\n",
    "We first start with an explicit model-based simulation. This means that we have a model of the DTMC in memory. This is fast and convenient if the model is available, but limits the size of models that we support.\n",
    "\n",
    "### DTMCs\n",
    "We first discuss the interface for DTMCs, without any nondeterminism.\n",
    "\n",
    "#### Explicit state-representations\n",
    "After importing some parts of stormpy as above, we start with creating a model, in this case a DTMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = stormpy.examples.files.prism_dtmc_die\n",
    "prism_program = stormpy.parse_prism_program(path)\n",
    "model = stormpy.build_model(prism_program)\n",
    "\n",
    "simulator = stormpy.simulator.create_simulator(model, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us simulate a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [0.0], {'init'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, [1.0], set())"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, [1.0], set())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, [1.0], {'done', 'five'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the simulator by restarting. We then do 3 steps. Every step returns a triple (state, reward, labels). In particular, the simulation above reflects a path s0, s2, s5, s11. Taking the transitions inbetween yields the reward as shown above. While states s2 and s5 are not labelled, state s0 is labelled with `init` and state s11 is labelled with `done` and `five`. Indeed we can check this information on the model that we used for the simulator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'done', 'five'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labeling.get_labels_of_state(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, [0.0], {'done', 'five'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, [0.0], {'done', 'five'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we are not leaving the state. In this case, we can never leave the state as state s11 is absorbing. The simulator detects and exposes this information via `simulator.is_done()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.is_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample more paths, yielding (potentially) different final states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 21, 9: 16, 10: 18, 11: 17, 12: 16, 8: 12}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.restart()\n",
    "final_outcomes = dict()\n",
    "for n in range(100):\n",
    "    while not simulator.is_done():\n",
    "        observation, reward, labels = simulator.step()\n",
    "    if observation not in final_outcomes:\n",
    "        final_outcomes[observation] = 1\n",
    "    else:\n",
    "        final_outcomes[observation] += 1\n",
    "    simulator.restart()\n",
    "final_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Program-level representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the same simulator but represent states symbolically, referring to the high-level description of the state rather than on its internal index. The advantage of this is that the process becomes independent of the underlying representation of the model. We first need to build the model with the required annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = stormpy.BuilderOptions()\n",
    "options.set_build_state_valuations()\n",
    "model = stormpy.build_sparse_model_with_options(prism_program, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create simulator that uses program-level state observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = stormpy.simulator.create_simulator(model, seed=42)\n",
    "simulator.set_observation_mode(stormpy.simulator.SimulatorObservationMode.PROGRAM_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"d\": 0,\\n    \"s\": 0\\n}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, reward, label = simulator.restart()\n",
    "str(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the state is now an object that describes the state in terms of the variables of prism program, in this case variables \"s\" and \"d\". \n",
    "\n",
    "We can use the simulator as before, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coin_flips']\n",
      "{\n",
      "    \"d\": 5,\n",
      "    \"s\": 7\n",
      "}: 18, {\n",
      "    \"d\": 4,\n",
      "    \"s\": 7\n",
      "}: 19, {\n",
      "    \"d\": 2,\n",
      "    \"s\": 7\n",
      "}: 13, {\n",
      "    \"d\": 6,\n",
      "    \"s\": 7\n",
      "}: 16, {\n",
      "    \"d\": 3,\n",
      "    \"s\": 7\n",
      "}: 14, {\n",
      "    \"d\": 1,\n",
      "    \"s\": 7\n",
      "}: 20\n"
     ]
    }
   ],
   "source": [
    "simulator.restart()\n",
    "final_outcomes = dict()\n",
    "print(simulator.get_reward_names())\n",
    "for n in range(100):\n",
    "    while not simulator.is_done():\n",
    "        observation, reward, labels = simulator.step()\n",
    "    if observation not in final_outcomes:\n",
    "        final_outcomes[observation] = 1\n",
    "    else:\n",
    "        final_outcomes[observation] += 1\n",
    "    simulator.restart()\n",
    "print(\", \".join([f\"{str(k)}: {v}\" for k, v in final_outcomes.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, we can represent states both explicitly or symbolically. We only discuss the explicit representation here. With nondeterminism, we now must resolve this nondeterminism externally. That is, the step argument now takes an argument, which we may pick randomly or in a more intelligent manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --act=1--> 2 --act=0--> 2 --act=0--> 4 --act=2--> 1 --act=1--> 3 --act=1--> 3 --act=2--> 7 --act=2--> 3 --act=0--> 1 --act=2--> 4 --act=1--> 4 --act=2--> 4 --act=3--> 8 --act=0--> 5 --act=0--> 8 --act=3--> 12 --act=0--> 12 --act=0--> 9 --act=0--> 9 --act=1--> 5\n",
      "------\n",
      "0 --act=1--> 0 --act=0--> 0 --act=1--> 2 --act=1--> 0 --act=0--> 0 --act=0--> 1 --act=0--> 0 --act=1--> 2 --act=2--> 5 --act=0--> 8 --act=1--> 11 --act=2--> 7 --act=2--> 3 --act=2--> 7 --act=2--> 3 --act=2--> 3 --act=1--> 3 --act=2--> 3 --act=0--> 1 --act=1--> 3\n",
      "------\n",
      "0 --act=0--> 1 --act=2--> 4 --act=3--> 4 --act=3--> 4 --act=1--> 4 --act=1--> 7 --act=1--> 10 --act=2--> 10 --act=1--> 6 --act=0--> 3 --act=2--> 7 --act=0--> 4 --act=0--> 2 --act=0--> 4 --act=3--> 8 --act=0--> 5 --act=2--> 9 --act=1--> 5 --act=2--> 9 --act=1--> 9\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(23)\n",
    "path = stormpy.examples.files.prism_mdp_slipgrid\n",
    "prism_program = stormpy.parse_prism_program(path)\n",
    "\n",
    "model = stormpy.build_model(prism_program)\n",
    "simulator = stormpy.simulator.create_simulator(model, seed=42)\n",
    "# 3 paths of at most 20 steps.\n",
    "paths = []\n",
    "for m in range(3):\n",
    "    path = []\n",
    "    state, reward, labels = simulator.restart()\n",
    "    path = [f\"{state}\"]\n",
    "    for n in range(20):\n",
    "        actions = simulator.available_actions()\n",
    "        select_action = random.randint(0, len(actions) - 1)\n",
    "        path.append(f\"--act={actions[select_action]}-->\")\n",
    "        state, reward, labels = simulator.step(actions[select_action])\n",
    "        path.append(f\"{state}\")\n",
    "        if simulator.is_done():\n",
    "            break\n",
    "    paths.append(path)\n",
    "for path in paths:\n",
    "    print(\" \".join(path))\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the actions are internal numbers. Often, a program gives semantically meaningful names, such as moving `north`, `east`, `west` and `south` in a grid with program variables reflecting the `x` and `y` location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1) --west--> (1,2) --south--> (1,2) --east--> (1,2) --east--> (1,1) --west--> (1,2) --east--> (1,1) --south--> (2,1) --south--> (2,1) --north--> (1,1) --south--> (2,1) --west--> (2,1) --north--> (2,1) --west--> (2,2) --west--> (2,2) --south--> (3,2) --east--> (3,2) --south--> (4,2) --west--> (4,2) --west--> (4,2) --north--> (3,2)\n",
      "(1,1) --west--> (1,1) --south--> (1,1) --west--> (1,2) --south--> (1,2) --south--> (1,2) --west--> (1,3) --east--> (1,2) --east--> (1,2) --south--> (2,2) --south--> (3,2) --south--> (4,2) --west--> (4,3) --north--> (3,3) --south--> (4,3) --west--> (4,4) --north--> (3,4) --east--> (3,3) --west--> (3,3) --north--> (2,3) --east--> (2,3)\n",
      "(1,1) --south--> (2,1) --south--> (3,1) --south--> (3,1) --north--> (2,1) --north--> (1,1) --south--> (2,1) --south--> (3,1) --south--> (3,1) --west--> (3,2) --south--> (3,2) --west--> (3,3) --east--> (3,2) --south--> (3,2) --north--> (3,2) --north--> (3,2) --south--> (3,2) --south--> (4,2) --east--> (4,1) --north--> (4,1) --west--> (4,2)\n"
     ]
    }
   ],
   "source": [
    "options = stormpy.BuilderOptions()\n",
    "options.set_build_choice_labels()\n",
    "options.set_build_state_valuations()\n",
    "model = stormpy.build_sparse_model_with_options(prism_program, options)\n",
    "simulator = stormpy.simulator.create_simulator(model, seed=42)\n",
    "simulator.set_action_mode(stormpy.simulator.SimulatorActionMode.GLOBAL_NAMES)\n",
    "simulator.set_observation_mode(stormpy.simulator.SimulatorObservationMode.PROGRAM_LEVEL)\n",
    "# 3 paths of at most 20 steps.\n",
    "paths = []\n",
    "for m in range(3):\n",
    "    path = []\n",
    "    state, reward, labels = simulator.restart()\n",
    "    path = [f\"({state['x']},{state['y']})\"]\n",
    "    for n in range(20):\n",
    "        actions = simulator.available_actions()\n",
    "        select_action = random.randint(0, len(actions) - 1)\n",
    "        path.append(f\"--{actions[select_action]}-->\")\n",
    "        state, reward, labels = simulator.step(actions[select_action])\n",
    "        path.append(f\"({state['x']},{state['y']})\")\n",
    "        if simulator.is_done():\n",
    "            break\n",
    "    paths.append(path)\n",
    "for path in paths:\n",
    "    print(\" \".join(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program-level simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a program-level simulator, which does not require putting the model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = stormpy.simulator.create_simulator(prism_program, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1) --0--> (2,1) --0--> (1,1) --1--> (1,2) --1--> (1,1) --1--> (1,2) --0--> (2,2) --3--> (2,3) --0--> (1,3) --2--> (1,3) --2--> (1,4) --0--> (2,4) --2--> (2,3) --2--> (2,2) --3--> (2,2) --3--> (2,3) --2--> (2,2) --0--> (2,2) --2--> (2,2) --0--> (1,2) --0--> (2,2)\n",
      "(1,1) --0--> (2,1) --1--> (2,1) --2--> (2,2) --3--> (2,2) --1--> (2,2) --1--> (3,2) --0--> (2,2) --2--> (2,1) --2--> (2,2) --0--> (2,2) --1--> (3,2) --3--> (3,3) --3--> (3,3) --2--> (3,2) --0--> (2,2) --2--> (2,2) --3--> (2,2) --0--> (1,2) --0--> (2,2) --3--> (2,3)\n",
      "(1,1) --0--> (2,1) --2--> (2,2) --0--> (1,2) --0--> (2,2) --3--> (2,2) --3--> (2,3) --0--> (1,3) --1--> (1,3) --2--> (1,4) --1--> (1,4) --1--> (1,3) --2--> (1,4) --0--> (2,4) --2--> (2,3) --2--> (2,2) --2--> (2,2) --0--> (1,2) --0--> (2,2) --0--> (2,2) --3--> (2,3)\n"
     ]
    }
   ],
   "source": [
    "# 3 paths of at most 20 steps.\n",
    "paths = []\n",
    "for m in range(3):\n",
    "    path = []\n",
    "    state, reward, labels = simulator.restart()\n",
    "    path = [f\"({state['x']},{state['y']})\"]\n",
    "    for n in range(20):\n",
    "        actions = simulator.available_actions()\n",
    "        select_action = random.randint(0, len(actions) - 1)\n",
    "        path.append(f\"--{actions[select_action]}-->\")\n",
    "        state, reward, labels = simulator.step(actions[select_action])\n",
    "        path.append(f\"({state['x']},{state['y']})\")\n",
    "        if simulator.is_done():\n",
    "            break\n",
    "    paths.append(path)\n",
    "for path in paths:\n",
    "    print(\" \".join(path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
