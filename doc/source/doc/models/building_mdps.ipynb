{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov decision processes (MDPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In [Discrete-time Markov chains (DTMCs)](building_dtmcs.ipynb) we modelled Knuth-Yao’s model of a fair die by the means of a DTMC.\n",
    "In the following we extend this model with nondeterministic choice by building a Markov decision process.\n",
    "\n",
    "[01-building-mdps.py](https://github.com/moves-rwth/stormpy/blob/master/examples/building_mdps/01-building-mdps.py)\n",
    "\n",
    "First, we import Stormpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import stormpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Matrix\n",
    "\n",
    "Since we want to build a nondeterminstic model, we create a transition matrix with a custom row group for each state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "builder = stormpy.SparseMatrixBuilder(rows=0, columns=0, entries=0, force_dimensions=False, has_custom_row_grouping=True, row_groups=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need more than one row for the transitions starting in state 0 because a nondeterministic choice over the actions is available.\n",
    "Therefore, we start a new group that will contain the rows representing actions of state 0.\n",
    "Note that the row group needs to be added before any entries are added to the group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "builder.new_row_group(0)\n",
    "builder.add_next_value(0, 1, 0.5)\n",
    "builder.add_next_value(0, 2, 0.5)\n",
    "builder.add_next_value(1, 1, 0.2)\n",
    "builder.add_next_value(1, 2, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have two nondeterministic choices in state 0.\n",
    "With choice 0 we have probability 0.5 to got to state 1 and probability 0.5 to got to state 2.\n",
    "With choice 1 we got to state 1 with probability 0.2 and go to state 2 with probability 0.8.\n",
    "\n",
    "For the remaining states, we need to specify the starting rows of each row group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "builder.new_row_group(2)\n",
    "builder.add_next_value(2, 3, 0.5)\n",
    "builder.add_next_value(2, 4, 0.5)\n",
    "builder.new_row_group(3)\n",
    "builder.add_next_value(3, 5, 0.5)\n",
    "builder.add_next_value(3, 6, 0.5)\n",
    "builder.new_row_group(4)\n",
    "builder.add_next_value(4, 7, 0.5)\n",
    "builder.add_next_value(4, 1, 0.5)\n",
    "builder.new_row_group(5)\n",
    "builder.add_next_value(5, 8, 0.5)\n",
    "builder.add_next_value(5, 9, 0.5)\n",
    "builder.new_row_group(6)\n",
    "builder.add_next_value(6, 10, 0.5)\n",
    "builder.add_next_value(6, 11, 0.5)\n",
    "builder.new_row_group(7)\n",
    "builder.add_next_value(7, 2, 0.5)\n",
    "builder.add_next_value(7, 12, 0.5)\n",
    "\n",
    "for s in range(8, 14):\n",
    "    builder.new_row_group(s)\n",
    "    builder.add_next_value(s, s - 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we build the transition matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "transition_matrix = builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling\n",
    "\n",
    "We have seen the construction of a state labeling in the previous example for [building a DTMC](building_dtmcs.ipynb). Therefore we omit the description here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "state_labeling = stormpy.storage.StateLabeling(13)\n",
    "labels = {\"init\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"done\", \"deadlock\"}\n",
    "for label in labels:\n",
    "    state_labeling.add_label(label)\n",
    "\n",
    "state_labeling.add_label_to_state(\"init\", 0)\n",
    "state_labeling.add_label_to_state(\"one\", 7)\n",
    "state_labeling.add_label_to_state(\"two\", 8)\n",
    "state_labeling.add_label_to_state(\"three\", 9)\n",
    "state_labeling.add_label_to_state(\"four\", 10)\n",
    "state_labeling.add_label_to_state(\"five\", 11)\n",
    "state_labeling.add_label_to_state(\"six\", 12)\n",
    "state_labeling.set_states(\"done\", stormpy.BitVector(13, [7, 8, 9, 10, 11, 12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice labeling\n",
    "We focus on the labeling of choices.\n",
    "Since in state 0 a nondeterministic choice over two actions is available, the total number of choices is 14.\n",
    "To distinguish those we can define a choice labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "choice_labeling = stormpy.storage.ChoiceLabeling(14)\n",
    "choice_labels = {\"a\", \"b\"}\n",
    "\n",
    "for label in choice_labels:\n",
    "    choice_labeling.add_label(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign the label ‘a’ to the first action of state 0 and ‘b’ to the second.\n",
    "Recall that those actions where defined in row one and two of the transition matrix respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "choice_labeling.add_label_to_choice(\"a\", 0)\n",
    "choice_labeling.add_label_to_choice(\"b\", 1)\n",
    "print(choice_labeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward models\n",
    "\n",
    "In this reward model the length of the action rewards coincides with the number of choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "reward_models = {}\n",
    "action_reward = [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "reward_models[\"coin_flips\"] = stormpy.SparseRewardModel(optional_state_action_reward_vector=action_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "We collect the components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "components = stormpy.SparseModelComponents(\n",
    "    transition_matrix=transition_matrix, state_labeling=state_labeling, reward_models=reward_models, rate_transitions=False\n",
    ")\n",
    "components.choice_labeling = choice_labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "mdp = stormpy.storage.SparseMdp(components)\n",
    "print(mdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partially observable Markov decision process (POMDPs)\n",
    "\n",
    "To build a partially observable Markov decision process (POMDP),\n",
    "components.observations can be set to a list of numbers that defines the status of the observables in each state."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "date": 1598178167.234528,
  "filename": "building_mdps.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "title": "Markov decision processes (MDPs)"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
